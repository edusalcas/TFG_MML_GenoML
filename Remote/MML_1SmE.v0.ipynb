{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Intro\n",
    " - **Project:** Meta Machine Learning\n",
    " - **Author:** Eduardo Salmerón Castaño\n",
    " - **Date Notebook Started:** 02.03.2020\n",
    "    - **Quick Description:** Notebook version of Meta ML.\n",
    "\n",
    "---\n",
    "### Quick Description: \n",
    "**Problem:** Obtain a Meta-ML model with one source.\n",
    "\n",
    "**Solution:** First prepare data for ML, then get level 1 experts and finally obtain the Meta-ML model. \n",
    "\n",
    "### Motivation/Background:\n",
    "You want to get a Meta-ML model.\n",
    "\n",
    "### Thoughts for Future Development of Code in this Notebook: \n",
    "- Select which algorithms you want to use for ML and Meta-ML.\n",
    "- Improve the accuracy.\n",
    "- Use GenoML functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "All imports needed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fromGenoToMLData as fm\n",
    "import genoMML as gm\n",
    "import pickle\n",
    "import os\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GenModels_1SmE function\n",
    "Main function that applies the Meta Learning 1SmE and returns the final results of the evaluation in the test set\n",
    "\n",
    "Parameters:\n",
    "\n",
    "&emsp;__workPath__: String with your workpath<br>\n",
    "&emsp;__path2Data__: Path to the folder that contains the PLINK files<br>\n",
    "&emsp;__path2packages__: Path to the folder that contains PLINK, PRSice and the GWAS<br>\n",
    "&emsp;__genoTrain__: String with the name of the cohort used for training<br>\n",
    "&emsp;__covsTrain__: String with the name of the covariates used for training<br>\n",
    "&emsp;__genoTest__: Vector with the names of the geno files for the cohort used in test<br>\n",
    "&emsp;__covsTest__: Vector with the names of the covs files for the cohort used in test<br>\n",
    "&emsp;__path2PCA__: Path to the set with the PCA applied to the cohorts<br>\n",
    "\n",
    "Return value:\n",
    "\n",
    "&emsp;The final results on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MML_1SmE(workPath,\n",
    "            path2Data,\n",
    "            path2packages,\n",
    "            genoTrain,\n",
    "            covsTrain,\n",
    "            genoTest,\n",
    "            covsTest,\n",
    "            path2PCA):\n",
    "    # Read PCAs\n",
    "    #pandas2ri.activate()\n",
    "\n",
    "    readRDS = robjects.r['readRDS']\n",
    "    pcaSET = readRDS(path2PCA)\n",
    "    \n",
    "    lworkPath = workPath + \"dataRepo/\"\n",
    "    try:\n",
    "        os.mkdir(lworkPath)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Create handler\n",
    "    if (os.path.isfile(lworkPath + \"mldatahandler.pydat\")): # If the handler already exists, read it\n",
    "        with open(lworkPath + 'mldatahandler.pydat', 'rb') as mldatahandler_file:\n",
    "            handlerML = pickle.load(mldatahandler_file)\n",
    "        print(lworkPath + 'mldatahandler.pydat' + \" already exists.\")\n",
    "    else:\n",
    "        handlerML = fm.fromGenoToMLdata(lworkPath,\n",
    "                                        path2Geno=path2Data + \"/\" + genoTrain,\n",
    "                                        path2Covs=path2Data + \"/\" + covsTrain,\n",
    "                                        predictor=\"DISEASE\",\n",
    "                                        path2GWAS=path2packages,  \n",
    "                                        path2PRSice=path2packages,  \n",
    "                                        path2plink=path2packages,\n",
    "                                        iter=1)\n",
    "    \n",
    "    # Generate k folds and obtain their level 1 experts\n",
    "    experts_L1 = gm.genModels_1SmE(workPath=lworkPath,\n",
    "                                   handlerMLdata=handlerML,\n",
    "                                   k=5)\n",
    "\n",
    "\n",
    "    # Obtain level 2 expert\n",
    "    expert_L2 = gm.trainAndTestMML_1SmE(experts_L1,\n",
    "                                        handlerML,\n",
    "                                        lworkPath)\n",
    "\n",
    "    # Test each cohort\n",
    "    for geno, covs in zip(genoTest, covsTest):\n",
    "        print()\n",
    "        print(\"#\" * 30)\n",
    "        print(\"Final Test with \" + geno + \"\\n\")\n",
    "\n",
    "        lworkPath = workPath + \"/\" + covs + \"/\"\n",
    "        try:\n",
    "            os.mkdir(lworkPath)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # generate mldata for the test repository\n",
    "        handlerTest = gm.prepareFinalTest(workPath=lworkPath,\n",
    "                                          path2Geno=path2Data + \"/\" + geno,\n",
    "                                          path2Covs=path2Data + \"/\" + covs,\n",
    "                                          predictor=\"PHENO_PLINK\",\n",
    "                                          snpsToPull=handlerML[\"snpsToPull\"])\n",
    "\n",
    "        with open(lworkPath + \"/handler- \" + geno + \".pydat\", 'wb') as handlerTest_file:\n",
    "            pickle.dump(handlerTest, handlerTest_file)\n",
    "\n",
    "        # obtain final evaluation results\n",
    "        finalResult = gm.finalTest_1SmE(lworkPath,\n",
    "                                        expert_L2,\n",
    "                                        handlerTest,\n",
    "                                        experts_L1)\n",
    "\n",
    "        with open(lworkPath + \"/finalResults.pydat\", 'wb') as finalResult_file:\n",
    "            pickle.dump(finalResult, finalResult_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of the functionality\n",
    "In this section we use the upper function to explain: \n",
    " - An example of parameters we can use.\n",
    " - How we process the genotype data to obtain the dataforML file.\n",
    " - How we obtain level 1 experts from this processed data.\n",
    " - How we obtain final model from level 1 experts.\n",
    " - Test the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "The parameters we are using are:\n",
    " - genoTrain: We are using the spanish cohort for training, \"SPANISH\" indicates the file name.\n",
    " - covsTrain: The covariations file of the spanish cohort.\n",
    " - path2Data: This is the path to the files we are using are.\n",
    " - path2packages: This is the path to the packages we use (i.e. plink).\n",
    " - workPath: Path where we all files will be saved.\n",
    " - genoTest: Cohorts names we are using for test final model. We are using PPMI, HBS and PDBP cohorts.\n",
    " - covsTest: Covariations files of the cohorts we are using for test final model.\n",
    " - path2PCA: PCA file we will use in our trainig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genoTrain = \"SPANISH\" \n",
    "covsTrain = \"COVS_SPANISH\"\n",
    "path2Data = \"/home/edusal/data/FINALES\"\n",
    "path2packages = \"/home/edusal/packages/\"\n",
    "workPath = \"/home/edusal/MML-1SmE-4/\"\n",
    "genoTest = [\"PPMI\", \"HBS\", \"PDBP\"]\n",
    "covsTest = [\"COVS_\" + cov for cov in genoTest]\n",
    "path2PCA = '/home/edusal/OBTAIN_PCA/pcaSET.rds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain dataforML\n",
    "\n",
    "The first step is process our geno file so we can use it on the training process. We can do this with the function `fromGenoToMLData` from fromGenoToMLData.py (there is a notebook of this file that explains every function). This function basically reads our files, splits the data (by default 75-25), selects the most relevants SNPs (we use plink) and finally creates the dataforML file. Spanish cohort's predictor is called \"DISEASE\", we have to indicate it in the parameter \"predictor\".\n",
    "\n",
    "If the dataforML file is already created we skip it so we dont waste time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "trainFoldFiles\n",
      "Creating genotype data for fold 1 and train with command /home/edusal/packages/plink --bfile /home/edusal/data/FINALES/SPANISH --keep /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//COVS_SPANISHtrain.ids --make-bed --out /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//SPANISHtrain.1\n",
      "\n",
      "1\n",
      "testFoldFiles\n",
      "Creating genotype data for fold 1 and test with command /home/edusal/packages/plink --bfile /home/edusal/data/FINALES/SPANISH --keep /home/edusal/MML-1SmE-4/dataRepo/Foldtest1//COVS_SPANISHtest.ids --make-bed --out /home/edusal/MML-1SmE-4/dataRepo/Foldtest1//SPANISHtest.1\n",
      "\n",
      "1\n",
      "trainFoldFiles\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//SPANISHtrain.1 already created, skipping\n",
      "\n",
      "1\n",
      "testFoldFiles\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtest1//SPANISHtest.1 already created, skipping\n",
      "\n",
      "The covstr is --cov-file /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//COVS_train1.cov \n",
      "(5710, 24)\n",
      "The covstr is --cov-file /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//COVS_train1.cov \n",
      "The command to run: Rscript /home/edusal/packages/PRSice.R --binary-target T --prsice /home/edusal/packages/PRSice_linux -n 1 --out /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp --pheno-file /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//MyPhenotype1train.pheno -t /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//SPANISHtrain.1 -b /home/edusal/packages//RISK_noSpain_MAF0.05.tab --cov-file /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//COVS_train1.cov  --print-snp --score std --perm 10000  --bar-levels 5E-8,4E-8,3E-8,2E-8,1E-8,9E-7,8E-7,7E-7,6E-7,5E-7,4E-7,3E-7,2E-7,1E-7,9E-6,8E-6,7E-6,6E-6,5E-6,4E-6,3E-6,2E-6,1E-6,9E-5,8E-5,7E-5,6E-5,5E-5,4E-5,3E-5,2E-5,1E-5,9E-4,8E-4,7E-4,6E-4,5E-4,4E-4,3E-4,2E-4,1E-4,9E-3,8E-3,7E-3,6E-3,5E-3,4E-3,3E-3,2E-3,1E-3,9E-2,8E-2,7E-2,6E-2,5E-2,4E-2,3E-2,2E-2,1E-2,9E-1,8E-1,7E-1,6E-1,5E-1,4E-1,3E-1,2E-1,1E-1,1  --fastscore --binary-target True --beta --snp MarkerName --A1 Allele1 --A2 Allele2 --stat Effect --se StdErr --pvalue P-value\n",
      "The command to run: cut -f 2 /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snp > /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull\n",
      "The command to run: awk 'NR == 2 {print $3}' /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.summary\n",
      "The command to run: /home/edusal/packages/plink --bfile /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//SPANISHtrain.1 --extract /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull --clump /home/edusal/packages//RISK_noSpain_MAF0.05.tab --clump-p1 5e-05 --clump-p2 5e-05 --clump-snp-field MarkerName --clump-field P-value --clump-r2 0.1 --clump-kb 250 --out /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.tempClumps\n",
      "The command to run: cut -f 3 /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.tempClumps.clumped > /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2\n",
      "The COMMAND: /home/edusal/packages/plink --bfile /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1/SPANISHtrain.1 --extract /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2 --recode A --out /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.reduced_genos\n",
      "The command to run: cut -f 1 /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2 > /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.reduced_genos_snpList\n",
      "Number of folds here 1\n",
      "\n",
      "1\n",
      "trainFoldFiles\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//SPANISHtrain.1 already created, skipping\n",
      "\n",
      "1\n",
      "testFoldFiles\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtest1//SPANISHtest.1 already created, skipping\n",
      "\n",
      "void\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2\n",
      "We are going to generate a SNP list from a SNP pool selected outside this handler\n",
      "MERGING 3 FILES\n",
      "Index(['PHENO', 'ID', 'AGE', 'SEX', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6',\n",
      "       ...\n",
      "       '21:24225477_G', '21:38770530_C', '21:38803972_G', '21:41430388_A',\n",
      "       '21:41435470_G', '21:41976993_A', '21:43428378_A', '22:41627924_T',\n",
      "       '22:42216326_G', '22:50794282_A'],\n",
      "      dtype='object', length=675)\n",
      "First 100 variable names for your file below, the rest are likely just more genotypes...\n",
      "Index(['PHENO', 'ID', 'AGE', 'SEX', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6',\n",
      "       'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15',\n",
      "       'PC16', 'PC17', 'PC18', 'PC19', 'PC20', '1:7483351_C', '1:8495945_C',\n",
      "       '1:25793663_T', '1:53233374_C', '1:62737125_C', '1:67247035_C',\n",
      "       '1:78070458_T', '1:91093014_C', '1:93570368_G', '1:93820684_A',\n",
      "       '1:97334020_G', '1:145716763_A', '1:147007132_G', '1:154837939_G',\n",
      "       '1:155033317_T', '1:155042437_G', '1:155121143_G', '1:155205634_C',\n",
      "       '1:155310443_T', '1:155698425_T', '1:156063880_C', '1:156156789_G',\n",
      "       '1:157721533_C', '1:161269897_G', '1:161388960_T', '1:161478859_T',\n",
      "       '1:161658490_T', '1:171719769_T', '1:171741759_G', '1:194554730_G',\n",
      "       '1:200934410_A', '1:202115945_G', '1:205163798_G', '1:205643920_C',\n",
      "       '1:205661418_T', '1:205723572_C', '1:205727466_C', '1:205752690_C',\n",
      "       '1:220163026_C', '1:226916078_C', '1:226974228_A', '1:226983330_C',\n",
      "       '1:227740847_A', '1:228324167_C', '1:232669682_T', '1:243741941_C',\n",
      "       '2:23951108_A', '2:24241950_G', '2:29111099_C', '2:31876492_G',\n",
      "       '2:32503526_T', '2:32811909_A', '2:61763207_T', '2:62719212_A',\n",
      "       '2:69664976_T', '2:79119830_G', '2:88736950_T', '2:95555581_C',\n",
      "       '2:96025765_G', '2:97569119_T', '2:102142042_C', '2:102280435_A',\n",
      "       '2:102352361_C', '2:102368870_G', '2:102468624_G', '2:102604649_A',\n",
      "       '2:102658632_T', '2:123244583_T', '2:135287914_T', '2:135486894_G',\n",
      "       '2:135539967_C', '2:135907088_A', '2:136322676_G', '2:136380723_G',\n",
      "       '2:136608646_A', '2:141623643_C'],\n",
      "      dtype='object')\n",
      "... and the last 100 variable names for your file below...\n",
      "Index([], dtype='object')\n",
      "Your final file has 5710 samples, and 675 predictors for analysis\n",
      "Running command /home/edusal/packages/plink --bfile /home/edusal/MML-1SmE-4/dataRepo/Foldtest1//SPANISHtest.1 --keep /home/edusal/MML-1SmE-4/dataRepo/Foldtest1//COVS_test1.cov --extract /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.reduced_genos_snpList --recode A --out /home/edusal/MML-1SmE-4/dataRepo/Foldtest1//g-SPANISHtest.1-p-MyPhenotype1test-c-COVS_test1-a-NA.reduced_genos\n",
      "\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2\n",
      "MERGING 3 FILES\n",
      "Index(['PHENO', 'ID', 'AGE', 'SEX', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6',\n",
      "       ...\n",
      "       '21:24225477_G', '21:38770530_C', '21:38803972_G', '21:41430388_A',\n",
      "       '21:41435470_G', '21:41976993_A', '21:43428378_A', '22:41627924_T',\n",
      "       '22:42216326_G', '22:50794282_A'],\n",
      "      dtype='object', length=675)\n",
      "First 100 variable names for your file below, the rest are likely just more genotypes...\n",
      "Index(['PHENO', 'ID', 'AGE', 'SEX', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6',\n",
      "       'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15',\n",
      "       'PC16', 'PC17', 'PC18', 'PC19', 'PC20', '1:7483351_C', '1:8495945_C',\n",
      "       '1:25793663_T', '1:53233374_C', '1:62737125_C', '1:67247035_C',\n",
      "       '1:78070458_T', '1:91093014_C', '1:93570368_G', '1:93820684_A',\n",
      "       '1:97334020_G', '1:145716763_G', '1:147007132_G', '1:154837939_G',\n",
      "       '1:155033317_T', '1:155042437_G', '1:155121143_G', '1:155205634_C',\n",
      "       '1:155310443_T', '1:155698425_T', '1:156063880_C', '1:156156789_G',\n",
      "       '1:157721533_C', '1:161269897_G', '1:161388960_T', '1:161478859_T',\n",
      "       '1:161658490_T', '1:171719769_T', '1:171741759_G', '1:194554730_G',\n",
      "       '1:200934410_A', '1:202115945_G', '1:205163798_G', '1:205643920_C',\n",
      "       '1:205661418_T', '1:205723572_C', '1:205727466_C', '1:205752690_C',\n",
      "       '1:220163026_C', '1:226916078_C', '1:226974228_A', '1:226983330_C',\n",
      "       '1:227740847_A', '1:228324167_C', '1:232669682_T', '1:243741941_C',\n",
      "       '2:23951108_A', '2:24241950_G', '2:29111099_C', '2:31876492_G',\n",
      "       '2:32503526_T', '2:32811909_A', '2:61763207_T', '2:62719212_A',\n",
      "       '2:69664976_T', '2:79119830_G', '2:88736950_T', '2:95555581_C',\n",
      "       '2:96025765_G', '2:97569119_T', '2:102142042_C', '2:102280435_A',\n",
      "       '2:102352361_C', '2:102368870_G', '2:102468624_G', '2:102604649_A',\n",
      "       '2:102658632_T', '2:123244583_T', '2:135287914_T', '2:135486894_G',\n",
      "       '2:135539967_C', '2:135907088_A', '2:136322676_T', '2:136380723_G',\n",
      "       '2:136608646_A', '2:141623643_C'],\n",
      "      dtype='object')\n",
      "... and the last 100 variable names for your file below...\n",
      "Index([], dtype='object')\n",
      "Your final file has 1904 samples, and 675 predictors for analysis\n",
      "Your train dataset is at /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1/g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.dataForML\n",
      "Your test dataset is at/home/edusal/MML-1SmE-4/dataRepo/Foldtest1/g-SPANISHtest.1-p-MyPhenotype1test-c-COVS_test1-a-NA.dataForML\n"
     ]
    }
   ],
   "source": [
    "readRDS = robjects.r['readRDS']\n",
    "pcaSET = readRDS(path2PCA)\n",
    "\n",
    "lworkPath = workPath + \"dataRepo/\"\n",
    "try:\n",
    "    os.mkdir(lworkPath)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Create handler\n",
    "if (os.path.isfile(lworkPath + \"mldatahandler.pydat\")): # If the handler already exists, read it\n",
    "    with open(lworkPath + 'mldatahandler.pydat', 'rb') as mldatahandler_file:\n",
    "        handlerML = pickle.load(mldatahandler_file)\n",
    "    print(lworkPath + 'mldatahandler.pydat' + \" already exists.\")\n",
    "else:\n",
    "    handlerML = fm.fromGenoToMLdata(lworkPath,\n",
    "                                    path2Geno=path2Data + \"/\" + genoTrain,\n",
    "                                    path2Covs=path2Data + \"/\" + covsTrain,\n",
    "                                    predictor=\"DISEASE\",\n",
    "                                    path2GWAS=path2packages,  \n",
    "                                    path2PRSice=path2packages,  \n",
    "                                    path2plink=path2packages,\n",
    "                                    iter=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain level 1 experts\n",
    "\n",
    "Once we have the data prepared, we can obtain level 1 experts with the function `genModels_1SmE` from GenoMML.py. This function uses the training partition (75%) and train using cross-validation (5 folds , as indicated in the parameter k). In the training process we use some algorithms, in our case we are using 3 algorithms (see on GenoMML notebook). Finally we obtain an expert for each algorithm, we will use these models in metaML training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[]\n",
      "\n",
      "##############################\n",
      "RandomForestClassifier\n",
      "\n",
      "\n",
      "\t##########################\n",
      "\tFold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tAUC: 53.7116%\n",
      "\t\tAccuracy: 54.8656%\n",
      "\t\tBalanced Accuracy: 52.6616%\n",
      "\t\tKappa: 5.3930%\n",
      "\t\tLog Loss: 0.8318\n",
      "\t\tRuntime in seconds: 0.1729\n",
      "\n",
      "\t##########################\n",
      "\tFold 2\n",
      "\n",
      "\t\tAUC: 52.6127%\n",
      "\t\tAccuracy: 54.4022%\n",
      "\t\tBalanced Accuracy: 52.0490%\n",
      "\t\tKappa: 4.1273%\n",
      "\t\tLog Loss: 0.7473\n",
      "\t\tRuntime in seconds: 0.1633\n",
      "\n",
      "\t##########################\n",
      "\tFold 3\n",
      "\n",
      "\t\tAUC: 55.6702%\n",
      "\t\tAccuracy: 55.2363%\n",
      "\t\tBalanced Accuracy: 53.5188%\n",
      "\t\tKappa: 6.9208%\n",
      "\t\tLog Loss: 0.7201\n",
      "\t\tRuntime in seconds: 0.1591\n",
      "\n",
      "\t##########################\n",
      "\tFold 4\n",
      "\n",
      "\t\tAUC: 50.7346%\n",
      "\t\tAccuracy: 53.7106%\n",
      "\t\tBalanced Accuracy: 51.2984%\n",
      "\t\tKappa: 2.6460%\n",
      "\t\tLog Loss: 0.8487\n",
      "\t\tRuntime in seconds: 0.1578\n",
      "\n",
      "\t##########################\n",
      "\tFold 5\n",
      "\n",
      "\t\tAUC: 54.3138%\n",
      "\t\tAccuracy: 56.5863%\n",
      "\t\tBalanced Accuracy: 54.5729%\n",
      "\t\tKappa: 9.2073%\n",
      "\t\tLog Loss: 0.7711\n",
      "\t\tRuntime in seconds: 0.169\n",
      "\n",
      "##############################\n",
      "LogisticRegression\n",
      "\n",
      "\n",
      "\t##########################\n",
      "\tFold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tAUC: 59.9201%\n",
      "\t\tAccuracy: 60.7970%\n",
      "\t\tBalanced Accuracy: 57.7472%\n",
      "\t\tKappa: 16.0392%\n",
      "\t\tLog Loss: 0.7475\n",
      "\t\tRuntime in seconds: 0.3659\n",
      "\n",
      "\t##########################\n",
      "\tFold 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tAUC: 63.6805%\n",
      "\t\tAccuracy: 63.7627%\n",
      "\t\tBalanced Accuracy: 60.5315%\n",
      "\t\tKappa: 21.7793%\n",
      "\t\tLog Loss: 0.696\n",
      "\t\tRuntime in seconds: 0.4138\n",
      "\n",
      "\t##########################\n",
      "\tFold 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tAUC: 61.3824%\n",
      "\t\tAccuracy: 61.3531%\n",
      "\t\tBalanced Accuracy: 58.2988%\n",
      "\t\tKappa: 16.8824%\n",
      "\t\tLog Loss: 0.7116\n",
      "\t\tRuntime in seconds: 0.3786\n",
      "\n",
      "\t##########################\n",
      "\tFold 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tAUC: 59.2243%\n",
      "\t\tAccuracy: 58.5343%\n",
      "\t\tBalanced Accuracy: 55.9731%\n",
      "\t\tKappa: 12.2479%\n",
      "\t\tLog Loss: 0.748\n",
      "\t\tRuntime in seconds: 0.3975\n",
      "\n",
      "\t##########################\n",
      "\tFold 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tAUC: 62.1505%\n",
      "\t\tAccuracy: 60.5751%\n",
      "\t\tBalanced Accuracy: 59.0692%\n",
      "\t\tKappa: 18.1317%\n",
      "\t\tLog Loss: 0.7235\n",
      "\t\tRuntime in seconds: 0.4139\n",
      "\n",
      "##############################\n",
      "DecisionTreeClassifier\n",
      "\n",
      "\n",
      "\t##########################\n",
      "\tFold 1\n",
      "\n",
      "\t\tAUC: 52.9015%\n",
      "\t\tAccuracy: 54.0315%\n",
      "\t\tBalanced Accuracy: 52.9015%\n",
      "\t\tKappa: 5.7506%\n",
      "\t\tLog Loss: 15.88\n",
      "\t\tRuntime in seconds: 0.4455\n",
      "\n",
      "\t##########################\n",
      "\tFold 2\n",
      "\n",
      "\t\tAUC: 54.3427%\n",
      "\t\tAccuracy: 56.1631%\n",
      "\t\tBalanced Accuracy: 54.3427%\n",
      "\t\tKappa: 8.6681%\n",
      "\t\tLog Loss: 15.14\n",
      "\t\tRuntime in seconds: 0.4572\n",
      "\n",
      "\t##########################\n",
      "\tFold 3\n",
      "\n",
      "\t\tAUC: 55.7359%\n",
      "\t\tAccuracy: 57.1826%\n",
      "\t\tBalanced Accuracy: 55.7359%\n",
      "\t\tKappa: 11.2462%\n",
      "\t\tLog Loss: 14.79\n",
      "\t\tRuntime in seconds: 0.4548\n",
      "\n",
      "\t##########################\n",
      "\tFold 4\n",
      "\n",
      "\t\tAUC: 53.4146%\n",
      "\t\tAccuracy: 54.7310%\n",
      "\t\tBalanced Accuracy: 53.4146%\n",
      "\t\tKappa: 6.8108%\n",
      "\t\tLog Loss: 15.64\n",
      "\t\tRuntime in seconds: 0.4509\n",
      "\n",
      "\t##########################\n",
      "\tFold 5\n",
      "\n",
      "\t\tAUC: 54.9109%\n",
      "\t\tAccuracy: 56.6790%\n",
      "\t\tBalanced Accuracy: 54.9109%\n",
      "\t\tKappa: 9.8401%\n",
      "\t\tLog Loss: 14.96\n",
      "\t\tRuntime in seconds: 0.4684\n",
      "\n",
      "\n",
      "\n",
      "  Fold               Algorithm  AUC_Percent  Accuracy_Percent  \\\n",
      "0    5  RandomForestClassifier    54.313831         56.586271   \n",
      "1    2      LogisticRegression    63.680473         63.762743   \n",
      "2    3  DecisionTreeClassifier    55.735898         57.182576   \n",
      "\n",
      "   Balanced_Accuracy_Percent   Log_Loss  Sensitivity  Specificity       PPV  \\\n",
      "0                  54.572854   0.771106     0.650078     0.441379  0.632375   \n",
      "1                  60.531469   0.695971     0.763077     0.447552  0.676671   \n",
      "2                  55.735898  14.788614     0.619549     0.495169  0.663446   \n",
      "\n",
      "        NPV  Runtime_Seconds  \n",
      "0  0.460432         0.168999  \n",
      "1  0.554913         0.413800  \n",
      "2  0.447598         0.454808  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate k folds and obtain their level 1 experts\n",
    "experts_L1 = gm.genModels_1SmE(workPath=lworkPath,\n",
    "                               handlerMLdata=handlerML,\n",
    "                               k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output we can see some of the metrics obtained of the training process, such as AUC, accuracy or kappa for each algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain final model\n",
    "Now we can use models generated in the previous step for meta-ML in function `trainAndTestMML-1SmE`. For Meta-ML we will use test data (25%) and the predictions of this data from level 1 experts. After training with the same algorithms used in ML (but in a future version we will use a parameter to indicate the algorithms we want to use) and using also cross-validation with 5 folds, we obtain a Meta-ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################\n",
      "RandomForestClassifier\n",
      "\n",
      "\n",
      "\t##########################\n",
      "\tFold 1\n",
      "\n",
      "\t\tAUC: 44.0851%\n",
      "\t\tAccuracy: 46.0674%\n",
      "\t\tBalanced Accuracy: 44.4789%\n",
      "\t\tKappa: -11.0123%\n",
      "\t\tLog Loss: 0.8817\n",
      "\t\tRuntime in seconds: 0.03797\n",
      "\n",
      "\t##########################\n",
      "\tFold 2\n",
      "\n",
      "\t\tAUC: 54.7297%\n",
      "\t\tAccuracy: 52.2556%\n",
      "\t\tBalanced Accuracy: 51.0822%\n",
      "\t\tKappa: 2.1889%\n",
      "\t\tLog Loss: 0.7129\n",
      "\t\tRuntime in seconds: 0.03762\n",
      "\n",
      "\t##########################\n",
      "\tFold 3\n",
      "\n",
      "\t\tAUC: 51.7204%\n",
      "\t\tAccuracy: 55.2632%\n",
      "\t\tBalanced Accuracy: 53.9407%\n",
      "\t\tKappa: 7.8915%\n",
      "\t\tLog Loss: 0.7288\n",
      "\t\tRuntime in seconds: 0.03752\n",
      "\n",
      "\t##########################\n",
      "\tFold 4\n",
      "\n",
      "\t\tAUC: 53.2566%\n",
      "\t\tAccuracy: 53.3835%\n",
      "\t\tBalanced Accuracy: 51.4771%\n",
      "\t\tKappa: 3.0168%\n",
      "\t\tLog Loss: 0.8388\n",
      "\t\tRuntime in seconds: 0.03697\n",
      "\n",
      "\t##########################\n",
      "\tFold 5\n",
      "\n",
      "\t\tAUC: 51.8313%\n",
      "\t\tAccuracy: 54.5113%\n",
      "\t\tBalanced Accuracy: 53.4157%\n",
      "\t\tKappa: 6.5827%\n",
      "\t\tLog Loss: 0.7284\n",
      "\t\tRuntime in seconds: 0.03736\n",
      "\n",
      "##############################\n",
      "LogisticRegression\n",
      "\n",
      "\n",
      "\t##########################\n",
      "\tFold 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tAUC: 58.9288%\n",
      "\t\tAccuracy: 56.1798%\n",
      "\t\tBalanced Accuracy: 54.8466%\n",
      "\t\tKappa: 9.6799%\n",
      "\t\tLog Loss: 1.977\n",
      "\t\tRuntime in seconds: 0.08196\n",
      "\n",
      "\t##########################\n",
      "\tFold 2\n",
      "\n",
      "\t\tAUC: 58.6635%\n",
      "\t\tAccuracy: 57.1429%\n",
      "\t\tBalanced Accuracy: 56.8484%\n",
      "\t\tKappa: 13.6265%\n",
      "\t\tLog Loss: 1.634\n",
      "\t\tRuntime in seconds: 0.09474\n",
      "\n",
      "\t##########################\n",
      "\tFold 3\n",
      "\n",
      "\t\tAUC: 61.9529%\n",
      "\t\tAccuracy: 57.8947%\n",
      "\t\tBalanced Accuracy: 57.9890%\n",
      "\t\tKappa: 15.5795%\n",
      "\t\tLog Loss: 1.837\n",
      "\t\tRuntime in seconds: 0.07975\n",
      "\n",
      "\t##########################\n",
      "\tFold 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tAUC: 60.0691%\n",
      "\t\tAccuracy: 56.7669%\n",
      "\t\tBalanced Accuracy: 55.1828%\n",
      "\t\tKappa: 10.5294%\n",
      "\t\tLog Loss: 2.072\n",
      "\t\tRuntime in seconds: 0.09712\n",
      "\n",
      "\t##########################\n",
      "\tFold 5\n",
      "\n",
      "\t\tAUC: 67.2229%\n",
      "\t\tAccuracy: 62.0301%\n",
      "\t\tBalanced Accuracy: 61.4277%\n",
      "\t\tKappa: 22.0236%\n",
      "\t\tLog Loss: 1.437\n",
      "\t\tRuntime in seconds: 0.1051\n",
      "\n",
      "##############################\n",
      "DecisionTreeClassifier\n",
      "\n",
      "\n",
      "\t##########################\n",
      "\tFold 1\n",
      "\n",
      "\t\tAUC: 57.1656%\n",
      "\t\tAccuracy: 58.4270%\n",
      "\t\tBalanced Accuracy: 57.1656%\n",
      "\t\tKappa: 14.3117%\n",
      "\t\tLog Loss: 14.36\n",
      "\t\tRuntime in seconds: 0.06626\n",
      "\n",
      "\t##########################\n",
      "\tFold 2\n",
      "\n",
      "\t\tAUC: 56.7568%\n",
      "\t\tAccuracy: 57.5188%\n",
      "\t\tBalanced Accuracy: 56.7568%\n",
      "\t\tKappa: 13.5718%\n",
      "\t\tLog Loss: 14.67\n",
      "\t\tRuntime in seconds: 0.0664\n",
      "\n",
      "\t##########################\n",
      "\tFold 3\n",
      "\n",
      "\t\tAUC: 49.1078%\n",
      "\t\tAccuracy: 50.3759%\n",
      "\t\tBalanced Accuracy: 49.1078%\n",
      "\t\tKappa: -1.7798%\n",
      "\t\tLog Loss: 17.14\n",
      "\t\tRuntime in seconds: 0.06382\n",
      "\n",
      "\t##########################\n",
      "\tFold 4\n",
      "\n",
      "\t\tAUC: 51.8716%\n",
      "\t\tAccuracy: 53.0075%\n",
      "\t\tBalanced Accuracy: 51.8716%\n",
      "\t\tKappa: 3.7627%\n",
      "\t\tLog Loss: 16.23\n",
      "\t\tRuntime in seconds: 0.08211\n",
      "\n",
      "\t##########################\n",
      "\tFold 5\n",
      "\n",
      "\t\tAUC: 52.1265%\n",
      "\t\tAccuracy: 54.8872%\n",
      "\t\tBalanced Accuracy: 52.1265%\n",
      "\t\tKappa: 4.2362%\n",
      "\t\tLog Loss: 15.58\n",
      "\t\tRuntime in seconds: 0.06682\n",
      "  Fold               Algorithm  AUC_Percent  Accuracy_Percent  \\\n",
      "0    1  RandomForestClassifier    44.085119         46.067416   \n",
      "0    2  RandomForestClassifier    54.729730         52.255639   \n",
      "0    3  RandomForestClassifier    51.720430         55.263158   \n",
      "0    4  RandomForestClassifier    53.256551         53.383459   \n",
      "0    5  RandomForestClassifier    51.831325         54.511278   \n",
      "0    1      LogisticRegression    58.928778         56.179775   \n",
      "0    2      LogisticRegression    58.663536         57.142857   \n",
      "0    3      LogisticRegression    61.952921         57.894737   \n",
      "0    4      LogisticRegression    60.069105         56.766917   \n",
      "0    5      LogisticRegression    67.222892         62.030075   \n",
      "0    1  DecisionTreeClassifier    57.165605         58.426966   \n",
      "0    2  DecisionTreeClassifier    56.756757         57.518797   \n",
      "0    3  DecisionTreeClassifier    49.107817         50.375940   \n",
      "0    4  DecisionTreeClassifier    51.871581         53.007519   \n",
      "0    5  DecisionTreeClassifier    52.126506         54.887218   \n",
      "\n",
      "   Balanced_Accuracy_Percent   Log_Loss  Sensitivity  Specificity       PPV  \\\n",
      "0                  44.478865   0.881651     0.535032     0.354545  0.541935   \n",
      "0                  51.082226   0.712938     0.614865     0.406780  0.565217   \n",
      "0                  53.940715   0.728771     0.619355     0.459459  0.615385   \n",
      "0                  51.477109   0.838764     0.655629     0.373913  0.578947   \n",
      "0                  53.415663   0.728420     0.578313     0.490000  0.653061   \n",
      "0                  54.846555   1.977299     0.624204     0.472727  0.628205   \n",
      "0                  56.848374   1.634200     0.594595     0.542373  0.619718   \n",
      "0                  57.988957   1.836651     0.574194     0.585586  0.659259   \n",
      "0                  55.182839   2.071889     0.668874     0.434783  0.608434   \n",
      "0                  61.427711   1.436596     0.638554     0.590000  0.721088   \n",
      "0                  57.165605  14.358817     0.643312     0.500000  0.647436   \n",
      "0                  56.756757  14.672488     0.635135     0.500000  0.614379   \n",
      "0                  49.107817  17.139543     0.567742     0.414414  0.575163   \n",
      "0                  51.871581  16.230628     0.602649     0.434783  0.583333   \n",
      "0                  52.126506  15.581403     0.632530     0.410000  0.640244   \n",
      "\n",
      "        NPV  Runtime_Seconds  \n",
      "0  0.348214         0.037971  \n",
      "0  0.457143         0.037623  \n",
      "0  0.463636         0.037516  \n",
      "0  0.452632         0.036968  \n",
      "0  0.411765         0.037360  \n",
      "0  0.468468         0.081956  \n",
      "0  0.516129         0.094739  \n",
      "0  0.496183         0.079754  \n",
      "0  0.500000         0.097116  \n",
      "0  0.495798         0.105097  \n",
      "0  0.495495         0.066256  \n",
      "0  0.522124         0.066400  \n",
      "0  0.407080         0.063820  \n",
      "0  0.454545         0.082107  \n",
      "0  0.401961         0.066823  \n",
      "\n",
      "\n",
      "\n",
      "  Fold               Algorithm  AUC_Percent  Accuracy_Percent  \\\n",
      "0    3  RandomForestClassifier    51.720430         55.263158   \n",
      "1    5      LogisticRegression    67.222892         62.030075   \n",
      "2    1  DecisionTreeClassifier    57.165605         58.426966   \n",
      "\n",
      "   Balanced_Accuracy_Percent   Log_Loss  Sensitivity  Specificity       PPV  \\\n",
      "0                  53.940715   0.728771     0.619355     0.459459  0.615385   \n",
      "1                  61.427711   1.436596     0.638554     0.590000  0.721088   \n",
      "2                  57.165605  14.358817     0.643312     0.500000  0.647436   \n",
      "\n",
      "        NPV  Runtime_Seconds  \n",
      "0  0.463636         0.037516  \n",
      "1  0.495798         0.105097  \n",
      "2  0.495495         0.066256  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain level 2 expert\n",
    "expert_L2 = gm.trainAndTestMML_1SmE(experts_L1,\n",
    "                                    handlerML,\n",
    "                                    lworkPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before we see some metrics of the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our model\n",
    "For the testing part we use the 3 testing cohorts (PPMI, HBS and PDBP), for each one, we process test data with `prepareFinalTest` and test the model with `finalTest_1SmE`, this function first obtain the predictions of the data with level 1 experts and then predict data with the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################\n",
      "Final Test with PPMI\n",
      "\n",
      "The command to run: cp /home/edusal/data/FINALES/COVS_PPMI.cov /home/edusal/MML-1SmE-4//COVS_PPMI/\n",
      "Running command /home/edusal/packages/plink --bfile /home/edusal/data/FINALES/PPMI --extract /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2 --recode A --out /home/edusal/MML-1SmE-4//COVS_PPMI//g-PPMI-p-MyPhenotype-c-COVS_PPMI-a-NA.reduced_genos\n",
      "\n",
      "Running command cut -f 1 /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2 > /home/edusal/MML-1SmE-4//COVS_PPMI//g-PPMI-p-MyPhenotype-c-COVS_PPMI-a-NA.reduced_genos_snpList\n",
      "\n",
      "Number of folds here 1\n",
      "\n",
      "1\n",
      "trainFoldFiles\n",
      "1\n",
      "testFoldFiles\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2\n",
      "MERGING 3 FILES\n",
      "Index(['PHENO', 'ID', 'SEX', 'PHENO_PLINK_y', 'AGE', 'PC1', 'PC2', 'PC3',\n",
      "       'PC4', 'PC5',\n",
      "       ...\n",
      "       '19:10730352_G', '19:46158293_G', '20:3164686_C', '20:6008226_C',\n",
      "       '20:33435161_T', '21:16812882_T', '21:41430388_A', '21:43428378_A',\n",
      "       '22:41627924_T', '22:42216326_G'],\n",
      "      dtype='object', length=300)\n",
      "First 100 variable names for your file below, the rest are likely just more genotypes...\n",
      "Index(['PHENO', 'ID', 'SEX', 'PHENO_PLINK_y', 'AGE', 'PC1', 'PC2', 'PC3',\n",
      "       'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', '1:8495945_C',\n",
      "       '1:25793663_T', '1:67247035_C', '1:93570368_G', '1:155033317_T',\n",
      "       '1:155698425_T', '1:156063880_C', '1:156156789_G', '1:161478859_C',\n",
      "       '1:171719769_T', '1:171741759_G', '1:205163798_G', '1:205661418_T',\n",
      "       '1:205723572_C', '1:205727466_C', '1:205752690_C', '1:220163026_C',\n",
      "       '1:226916078_C', '1:232669682_T', '2:24241950_A', '2:31876492_G',\n",
      "       '2:32503526_T', '2:32811909_A', '2:69664976_T', '2:102352361_C',\n",
      "       '2:135287914_T', '2:135486894_G', '2:135539967_T', '2:135907088_G',\n",
      "       '2:136322676_T', '2:136608646_G', '2:148668509_T', '2:166138608_G',\n",
      "       '2:167072851_A', '2:169110394_T', '2:191300402_G', '2:209165083_T',\n",
      "       '2:231878875_C', '2:236943672_C', '2:239362573_G', '3:9504099_A',\n",
      "       '3:18201319_G', '3:28700178_A', '3:46531144_A', '3:48333546_T',\n",
      "       '3:48748989_G', '3:49025101_A', '3:49083566_A', '3:49356671_C',\n",
      "       '3:52338852_T', '3:52443280_G', '3:52649748_A', '3:122196892_T',\n",
      "       '3:151112968_A', '3:160812752_T', '3:161077630_G', '3:182673355_C',\n",
      "       '3:182760073_G', '3:182858287_C', '4:734351_A', '4:759463_A',\n",
      "       '4:808184_A', '4:826725_A', '4:861652_A', '4:941290_C', '4:951947_C',\n",
      "       '4:989713_C', '4:1001742_T', '4:1015789_C', '4:1030779_T',\n",
      "       '4:2937485_T', '4:15620408_C', '4:15702175_T', '4:15737348_G',\n",
      "       '4:15829612_A', '4:17976846_A', '4:77076710_A', '4:77111032_T',\n",
      "       '4:77147969_G', '4:77198054_T', '4:77202861_A', '4:77378302_C',\n",
      "       '4:90431418_T', '4:90474291_C', '4:90608959_T'],\n",
      "      dtype='object')\n",
      "... and the last 100 variable names for your file below...\n",
      "Index([], dtype='object')\n",
      "Your final file has 528 samples, and 300 predictors for analysis\n",
      "\t\tAUC: 48.9106%\n",
      "\t\tAccuracy: 60.0379%\n",
      "\t\tBalanced Accuracy: 48.4573%\n",
      "\t\tKappa: -3.4314%\n",
      "\t\tLog Loss: 1.448\n",
      "\n",
      "##############################\n",
      "Final Test with HBS\n",
      "\n",
      "The command to run: cp /home/edusal/data/FINALES/COVS_HBS.cov /home/edusal/MML-1SmE-4//COVS_HBS/\n",
      "Running command /home/edusal/packages/plink --bfile /home/edusal/data/FINALES/HBS --extract /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2 --recode A --out /home/edusal/MML-1SmE-4//COVS_HBS//g-HBS-p-MyPhenotype-c-COVS_HBS-a-NA.reduced_genos\n",
      "\n",
      "Running command cut -f 1 /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2 > /home/edusal/MML-1SmE-4//COVS_HBS//g-HBS-p-MyPhenotype-c-COVS_HBS-a-NA.reduced_genos_snpList\n",
      "\n",
      "Number of folds here 1\n",
      "\n",
      "1\n",
      "trainFoldFiles\n",
      "1\n",
      "testFoldFiles\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2\n",
      "MERGING 3 FILES\n",
      "Index(['PHENO', 'ID', 'SEX', 'PHENO_PLINK_y', 'AGE', 'PC1', 'PC2', 'PC3',\n",
      "       'PC4', 'PC5',\n",
      "       ...\n",
      "       '19:46158293_G', '20:3164686_C', '20:6008226_C', '20:33435161_T',\n",
      "       '20:46407509_T', '21:16812882_T', '21:41430388_A', '21:43428378_A',\n",
      "       '22:41627924_T', '22:42216326_G'],\n",
      "      dtype='object', length=303)\n",
      "First 100 variable names for your file below, the rest are likely just more genotypes...\n",
      "Index(['PHENO', 'ID', 'SEX', 'PHENO_PLINK_y', 'AGE', 'PC1', 'PC2', 'PC3',\n",
      "       'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', '1:8495945_C',\n",
      "       '1:25793663_T', '1:93570368_G', '1:155033317_T', '1:155310443_T',\n",
      "       '1:155698425_T', '1:156063880_C', '1:156156789_G', '1:161478859_T',\n",
      "       '1:171719769_T', '1:171741759_G', '1:205163798_G', '1:205661418_T',\n",
      "       '1:205723572_C', '1:205752690_C', '1:220163026_C', '1:226916078_C',\n",
      "       '1:232669682_T', '2:24241950_A', '2:31876492_G', '2:32503526_T',\n",
      "       '2:32811909_A', '2:69664976_T', '2:102352361_C', '2:135287914_T',\n",
      "       '2:135539967_T', '2:135907088_G', '2:136322676_T', '2:136380723_G',\n",
      "       '2:136608646_G', '2:148668509_T', '2:166138608_G', '2:167072851_A',\n",
      "       '2:169110394_T', '2:191300402_G', '2:209165083_T', '2:231878875_C',\n",
      "       '2:236943672_C', '2:239362573_G', '3:9504099_A', '3:18201319_G',\n",
      "       '3:28700178_A', '3:46531144_A', '3:48333546_T', '3:48748989_G',\n",
      "       '3:49025101_A', '3:49083566_A', '3:49356671_C', '3:52338852_T',\n",
      "       '3:52443280_G', '3:52649748_A', '3:122196892_T', '3:151112968_A',\n",
      "       '3:160812752_T', '3:161077630_G', '3:182673355_C', '3:182760073_G',\n",
      "       '3:182858287_C', '4:734351_A', '4:759463_A', '4:808184_A', '4:826725_A',\n",
      "       '4:861652_A', '4:941290_C', '4:951947_C', '4:989713_C', '4:1001742_T',\n",
      "       '4:1015789_C', '4:1030779_T', '4:2937485_T', '4:15620408_C',\n",
      "       '4:15702175_T', '4:15737348_G', '4:15829612_A', '4:17976846_A',\n",
      "       '4:77076710_A', '4:77111032_T', '4:77147969_G', '4:77198054_T',\n",
      "       '4:77202861_A', '4:77378302_C', '4:90431418_T', '4:90474291_C',\n",
      "       '4:90582181_C', '4:90608959_T'],\n",
      "      dtype='object')\n",
      "... and the last 100 variable names for your file below...\n",
      "Index([], dtype='object')\n",
      "Your final file has 999 samples, and 303 predictors for analysis\n",
      "\t\tAUC: 57.5668%\n",
      "\t\tAccuracy: 55.5556%\n",
      "\t\tBalanced Accuracy: 54.9008%\n",
      "\t\tKappa: 9.9046%\n",
      "\t\tLog Loss: 1.451\n",
      "\n",
      "##############################\n",
      "Final Test with PDBP\n",
      "\n",
      "The command to run: cp /home/edusal/data/FINALES/COVS_PDBP.cov /home/edusal/MML-1SmE-4//COVS_PDBP/\n",
      "Running command /home/edusal/packages/plink --bfile /home/edusal/data/FINALES/PDBP --extract /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2 --recode A --out /home/edusal/MML-1SmE-4//COVS_PDBP//g-PDBP-p-MyPhenotype-c-COVS_PDBP-a-NA.reduced_genos\n",
      "\n",
      "Running command cut -f 1 /home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2 > /home/edusal/MML-1SmE-4//COVS_PDBP//g-PDBP-p-MyPhenotype-c-COVS_PDBP-a-NA.reduced_genos_snpList\n",
      "\n",
      "Number of folds here 1\n",
      "\n",
      "1\n",
      "trainFoldFiles\n",
      "1\n",
      "testFoldFiles\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2\n",
      "/home/edusal/MML-1SmE-4/dataRepo/Foldtrain1//g-SPANISHtrain.1-p-MyPhenotype1train-c-COVS_train1-a-NA.temp.snpsToPull2\n",
      "MERGING 3 FILES\n",
      "Index(['PHENO', 'ID', 'SEX', 'PHENO_PLINK_y', 'AGE', 'PC1', 'PC2', 'PC3',\n",
      "       'PC4', 'PC5',\n",
      "       ...\n",
      "       '19:46158293_G', '20:3164686_C', '20:6008226_C', '20:33435161_T',\n",
      "       '20:46407509_T', '21:16812882_T', '21:41430388_A', '21:43428378_A',\n",
      "       '22:41627924_T', '22:42216326_G'],\n",
      "      dtype='object', length=306)\n",
      "First 100 variable names for your file below, the rest are likely just more genotypes...\n",
      "Index(['PHENO', 'ID', 'SEX', 'PHENO_PLINK_y', 'AGE', 'PC1', 'PC2', 'PC3',\n",
      "       'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', '1:8495945_C',\n",
      "       '1:25793663_T', '1:67247035_C', '1:93570368_G', '1:155033317_T',\n",
      "       '1:155310443_T', '1:155698425_T', '1:156063880_C', '1:156156789_G',\n",
      "       '1:161478859_T', '1:171719769_T', '1:171741759_G', '1:205163798_G',\n",
      "       '1:205661418_T', '1:205723572_C', '1:205727466_C', '1:205752690_C',\n",
      "       '1:220163026_C', '1:226916078_C', '1:232669682_T', '2:24241950_A',\n",
      "       '2:31876492_G', '2:32503526_T', '2:32811909_A', '2:69664976_T',\n",
      "       '2:102352361_C', '2:135287914_T', '2:135486894_G', '2:135539967_T',\n",
      "       '2:135907088_G', '2:136322676_T', '2:136380723_G', '2:136608646_G',\n",
      "       '2:148668509_T', '2:166138608_G', '2:167072851_A', '2:169110394_T',\n",
      "       '2:191300402_G', '2:209165083_T', '2:231878875_C', '2:236943672_C',\n",
      "       '2:239362573_G', '3:9504099_A', '3:18201319_G', '3:28700178_A',\n",
      "       '3:46531144_A', '3:48333546_T', '3:48748989_G', '3:49025101_A',\n",
      "       '3:49083566_A', '3:49356671_C', '3:52338852_T', '3:52443280_G',\n",
      "       '3:52649748_G', '3:122196892_T', '3:151112968_A', '3:160812752_T',\n",
      "       '3:161077630_G', '3:182673355_C', '3:182760073_G', '3:182858287_C',\n",
      "       '4:734351_A', '4:759463_A', '4:808184_A', '4:826725_A', '4:861652_A',\n",
      "       '4:941290_C', '4:951947_C', '4:989713_C', '4:1001742_T', '4:1015789_C',\n",
      "       '4:1030779_T', '4:2937485_T', '4:15620408_C', '4:15702175_T',\n",
      "       '4:15737348_G', '4:15829612_A', '4:17976846_A', '4:77076710_A',\n",
      "       '4:77111032_T', '4:77147969_G', '4:77198054_T', '4:77202861_A',\n",
      "       '4:77378302_C', '4:90431418_T'],\n",
      "      dtype='object')\n",
      "... and the last 100 variable names for your file below...\n",
      "Index([], dtype='object')\n",
      "Your final file has 792 samples, and 306 predictors for analysis\n",
      "\t\tAUC: 60.6780%\n",
      "\t\tAccuracy: 63.1313%\n",
      "\t\tBalanced Accuracy: 57.2433%\n",
      "\t\tKappa: 15.2258%\n",
      "\t\tLog Loss: 1.178\n"
     ]
    }
   ],
   "source": [
    "# Test each cohort\n",
    "for geno, covs in zip(genoTest, covsTest):\n",
    "    print()\n",
    "    print(\"#\" * 30)\n",
    "    print(\"Final Test with \" + geno + \"\\n\")\n",
    "\n",
    "    lworkPath = workPath + \"/\" + covs + \"/\"\n",
    "    try:\n",
    "        os.mkdir(lworkPath)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # generate mldata for the test repository\n",
    "    handlerTest = gm.prepareFinalTest(workPath=lworkPath,\n",
    "                                      path2Geno=path2Data + \"/\" + geno,\n",
    "                                      path2Covs=path2Data + \"/\" + covs,\n",
    "                                      predictor=\"PHENO_PLINK\",\n",
    "                                      snpsToPull=handlerML[\"snpsToPull\"])\n",
    "\n",
    "    with open(lworkPath + \"/handler- \" + geno + \".pydat\", 'wb') as handlerTest_file:\n",
    "        pickle.dump(handlerTest, handlerTest_file)\n",
    "\n",
    "    # obtain final evaluation results\n",
    "    finalResult = gm.finalTest_1SmE(lworkPath,\n",
    "                                    expert_L2,\n",
    "                                    handlerTest,\n",
    "                                    experts_L1)\n",
    "\n",
    "    with open(lworkPath + \"/finalResults.pydat\", 'wb') as finalResult_file:\n",
    "        pickle.dump(finalResult, finalResult_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this output we see the final results of our testing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
